{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def get_avg_length(review):\n",
    "    split = review.split()\n",
    "    length_each_word = [len(word) for word in split]\n",
    "    sum_lengths = sum(length_each_word)\n",
    "    return 0 if len(split) == 0 else sum_lengths/len(split)\n",
    "\n",
    "\n",
    "def get_review_length(review):\n",
    "    length = len(review.split())\n",
    "    return length\n",
    "\n",
    "def get_tweet_character_length(tweet):\n",
    "    characters = [character for character in tweet if character not in not_counted]\n",
    "    length = len(characters)\n",
    "    return length\n",
    "\n",
    "def remove_stopwords(review):\n",
    "    split = review.split()\n",
    "    new  = [word for word in split if word not in stop]\n",
    "    return \" \".join(new)\n",
    "\n",
    "def to_lower(review):\n",
    "    split = review.split()\n",
    "    new = [word.lower() for word in split]\n",
    "    return \" \".join(new)\n",
    "    \n",
    "\n",
    "def remove_small(review):\n",
    "    split = review.split()\n",
    "    new = [word for word in split if len(word) > 2]\n",
    "    return \" \".join(new)\n",
    "\n",
    "def remove_digits(review):\n",
    "    split = reviews.split()\n",
    "    new = [word for word in split if not word.isdigit()]\n",
    "    return \" \".join(new)\n",
    "    \n",
    "\n",
    "os.chdir(\"/Users/emmagoldberg/Downloads\")\n",
    "#read in our data\n",
    "amazon_alexa = pd.read_csv(\"amazon_alexa.tsv\", delimiter = '\\t')\n",
    "amazon_alexa['verified_reviews'] = amazon_alexa['verified_reviews'].astype(\"str\")\n",
    "amazon_alexa = amazon_alexa[amazon_alexa.verified_reviews!= '']\n",
    "#remove na rows\n",
    "amazon_alexa = amazon_alexa.dropna()\n",
    "#get the average rating and plot\n",
    "avg_rating = amazon_alexa['rating'].mean()\n",
    "rating_counts = amazon_alexa['rating'].value_counts()\n",
    "#rating_counts.plot(kind = 'bar', color = 'seagreen')\n",
    "#print(\"We can see that most reviews are 4 and 5 stars.\")\n",
    "\n",
    "#remove all but the reviews and rating column, as we are predicting ratings solely on text reviews\n",
    "cols_to_remove = ['date', 'variation', 'feedback']\n",
    "amazon_alexa = amazon_alexa.drop(cols_to_remove, axis = 1)\n",
    "#cleaning up our text reviews\n",
    "#remove punctuation\n",
    "amazon_alexa['verified_reviews'] = amazon_alexa['verified_reviews'].str.replace('[^\\w\\s]','')\n",
    "#remove stopwords\n",
    "amazon_alexa['verified_reviews'] = amazon_alexa['verified_reviews'].apply(lambda review: remove_stopwords(review))\n",
    "#change reviews to lowercase\n",
    "amazon_alexa['verified_reviews'] = amazon_alexa['verified_reviews'].apply(lambda review: to_lower(review))\n",
    "#remove words that are two or fewer characters\n",
    "amazon_alexa['verified_reviews'] = amazon_alexa['verified_reviews'].apply(lambda review: remove_small(review) )\n",
    "#remove most common words\n",
    "reviews_string = ' '.join(amazon_alexa['verified_reviews'])\n",
    "high_frequency = pd.Series(reviews_string.split()).value_counts()[:10]\n",
    "#high_frequency.plot(kind = 'barh')\n",
    "frequent_words = high_frequency.index\n",
    "amazon_alexa['verified_reviews'] = amazon_alexa['verified_reviews'].apply(lambda review: \" \".join(\n",
    "    word for word in review.split() if word not in frequent_words))\n",
    "\n",
    "#basic summary plots of our reviews after cleanup\n",
    "lengths = amazon_alexa['verified_reviews'].apply(lambda review: get_review_length(review))\n",
    "avg_lengths = amazon_alexa['verified_reviews'].apply(lambda review: get_avg_length(review))\n",
    "\n",
    "summary = pd.DataFrame(dict(avg_rating = avg_rating, avg_review_length = lengths.mean(),\n",
    "                           avg_word_length = avg_lengths.mean()), index = [0])\n",
    "print(summary.head())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.hist(lengths, bins=10, color = 'lightskyblue')\n",
    "plt.xlim(0, 130)\n",
    "plt.xlabel(\"Review Lengths\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(avg_lengths, bins=20, color = 'blue')\n",
    "plt.xlim(0, 20)\n",
    "plt.xlabel(\"Average Word Lengths Per Review\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"We can see most reviews are between 0 and 25 words, after cleanup.\")\n",
    "print(\"We can also see that it is most common for the average word length in a review to be 3-8.\")\n",
    "import numpy as np\n",
    "#create the term-frequency matrix\n",
    "my_vec = CountVectorizer(max_features = 300 )\n",
    "X = my_vec.fit_transform(amazon_alexa['verified_reviews'])\n",
    "df = pd.DataFrame(X.toarray(), columns = my_vec.get_feature_names())\n",
    "df['rating'] = amazon_alexa['rating']\n",
    "amazon_alexa = df\n",
    "X = amazon_alexa.drop(['rating'], axis = 1)\n",
    "y = amazon_alexa['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#get our model\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {'n_estimators': np.arange(100, 1100, 100).tolist(), 'min_samples_split': np.arange(50, 200, 10).tolist()}\n",
    "grid_search = GridSearchCV(rf, parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "params = grid_search.best_params_\n",
    "\n",
    "#refit with best parameters\n",
    "rf = RandomForestClassifier(**params)\n",
    "rf.fit(X_train, y_train)\n",
    "print(params)\n",
    "print(\"Our training score is:\", rf.score(X_train, y_train))\n",
    "print(\"Our test set score is\", rf.score(X_test, y_test))\n",
    "\n",
    "#print out our classification report\n",
    "predictions = rf.predict(X_test)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"\\n\", class_report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
